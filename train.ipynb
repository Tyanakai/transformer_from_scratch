{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cidhDHT9NvoNMk0SIyliKsh0uxiQTGa9",
      "authorship_tag": "ABX9TyO5ytL2av3NNxSSm4A0zJs/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyanakai/transformer_from_scratch/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf-0qW-An2kE"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRRRh8zgwgHl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIYsmCsqwnBf"
      },
      "source": [
        "class Config:\n",
        "    train_file = \"date.txt\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD7AVJ3RwIpG"
      },
      "source": [
        "DRIVE = \"/content/drive/MyDrive/portfolio/transformer_study\"\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4B1-B9zs_P"
      },
      "source": [
        "## preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JR7MuTFwyjN"
      },
      "source": [
        "with open(os.path.join(DRIVE, Config.train_file), mode=\"r\") as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uKVMOtrpxcNb",
        "outputId": "387352c9-e5fc-4066-8e1a-6b11a0d0e478"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'september 27, 1994           _1994-09-27\\nAugust 19, 2003              _2003-08-19\\n2/10/93           '"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsvEP6SwxdcJ"
      },
      "source": [
        "text_x = []\n",
        "text_y = []\n",
        "\n",
        "for line in text.split(\"\\n\")[:-1]:\n",
        "    text_x.append(line[:-11].lower().lstrip())\n",
        "    text_y.append(line[-10:].lstrip())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApsiwTn-0GA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa3d5a80-7e9c-4fa5-ca86-44f3ad912a1b"
      },
      "source": [
        "text_x[-1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thursday, november 20, 1980  '"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MzQAv_S0KSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ca70a20-4a06-4aa0-906c-cf5a0ef2a1da"
      },
      "source": [
        "text_y[-1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1980-11-20'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4daI9TvCra2l"
      },
      "source": [
        "class Tokenizer():\n",
        "\n",
        "    def __init__(self, text_list):\n",
        "        self.text_list = text_list\n",
        "\n",
        "\n",
        "    def pad_text(self, text):\n",
        "        # 文末の空白をpad文字で埋める\n",
        "        last_char_idx = len(text.strip())\n",
        "        text = text[:last_char_idx] + \"＠\" * (len(text) - last_char_idx)\n",
        "        return text\n",
        "\n",
        "\n",
        "    def create_char_list(self):\n",
        "        # 入力文字列を文字に分解する\n",
        "        self.char_list = []\n",
        "        for text in self.text_list:\n",
        "            text = self.pad_text(text) # 文末の空白をpad文字で埋める\n",
        "            self.char_list.append(list(text)) # 文字に分解しリスト化\n",
        "\n",
        "    \n",
        "    def create_char_id_dict(self):\n",
        "        # 出現文字にidを対応させる\n",
        "        self.id_char_dict = dict()\n",
        "        self.char_id_dict = dict()\n",
        "        self.unique_char = np.unique(self.char_list)\n",
        "        \n",
        "        for id, c in enumerate(self.unique_char):\n",
        "            self.id_char_dict[id] = c\n",
        "            self.char_id_dict[c] = id\n",
        "\n",
        "\n",
        "    def attention_mask(self):\n",
        "        # attention_maskを作る\n",
        "        attention_mask = []\n",
        "        for line in self.char_list:\n",
        "            chars = np.array(line) # 文字リストをnp.array化\n",
        "            attention_mask.append((chars != \"＠\") * 1) # 文字が＠ではない場所が1となる\n",
        "        return np.array(attention_mask)\n",
        "\n",
        "\n",
        "    def tokenize(self):\n",
        "        # 文字列を文字に分解しリスト化\n",
        "        self.create_char_list()\n",
        "        \n",
        "        # 出現文字にidを対応させる\n",
        "        self.create_char_id_dict()\n",
        "\n",
        "        # 文字をidに変換する\n",
        "        token_list = []\n",
        "        for text in self.text_list:\n",
        "            token_list.append([self.char_id_dict[c] for c in text])\n",
        "\n",
        "        return np.array(token_list)\n",
        "\n",
        "\n",
        "    def detokenize(self, token_list):\n",
        "        for line in token_list:\n",
        "            char_list = [self.id_char_dict[t] for t in line]\n",
        "        return char_list"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_tokenizer = Tokenizer(text_x)\n",
        "encoder_token_list = encoder_tokenizer.tokenize()\n",
        "encoder_attention_mask = encoder_tokenizer.attention_mask()\n",
        "encoder_num_char = encoder_tokenizer.unique_char.shape[0]\n",
        "\n",
        "decoder_tokenizer = Tokenizer(text_y)\n",
        "decoder_token_list = decoder_tokenizer.tokenize()\n",
        "decoder_attention_mask = decoder_tokenizer.attention_mask()\n",
        "decoder_num_char = decoder_tokenizer.unique_char.shape[0]"
      ],
      "metadata": {
        "id": "U6gUE4EHDofE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "M3u_HxuWKhQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P94C7y6nIuW4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}