{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1cidhDHT9NvoNMk0SIyliKsh0uxiQTGa9",
      "authorship_tag": "ABX9TyMhaC6gXCQCTaPwLUxj1cBR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyanakai/transformer_from_scratch/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfomer訓練\n",
        "本ノートブックでは、スクラッチ実装したTransformerを訓練します。<br>\n",
        "訓練データとして、斎藤 康毅氏著「ゼロから作るDeep Learning ②」で使用されていた、[こちらの日付変換データ](https://github.com/oreilly-japan/deep-learning-from-scratch-2/blob/master/dataset/date.txt)をお借りしました。<br>\n",
        "多様な形式で日付を表現する文字列から、YYYY-MM-DD形式の文字列を予測するタスクとなっています。\n",
        "\n"
      ],
      "metadata": {
        "id": "TmQ0MDHNrnob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境、事前準備\n",
        "本ノートブックは、上記の日付データをGoogle Driveの`/portfolio/transformer_from_scratch`フォルダ下に保存した上で、Google Colaboratoryでの実行を想定しています。<br>"
      ],
      "metadata": {
        "id": "4c66p6XyvyD6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf-0qW-An2kE"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRRRh8zgwgHl"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD7AVJ3RwIpG"
      },
      "source": [
        "DRIVE = \"/content/drive/MyDrive/portfolio/transformer_from_scratch\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4B1-B9zs_P"
      },
      "source": [
        "## load & preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JR7MuTFwyjN"
      },
      "source": [
        "with open(os.path.join(DRIVE, \"date.txt\"), mode=\"r\") as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uKVMOtrpxcNb",
        "outputId": "c79cb635-86aa-468a-a85c-a72116063fb3"
      },
      "source": [
        "# データの境は\\nで区切られています。\n",
        "text[:200]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'september 27, 1994           _1994-09-27\\nAugust 19, 2003              _2003-08-19\\n2/10/93                      _1993-02-10\\n10/31/90                     _1990-10-31\\nTUESDAY, SEPTEMBER 25, 1984  _1984-0'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsvEP6SwxdcJ"
      },
      "source": [
        "encoder_text = []\n",
        "decoder_text = []\n",
        "\n",
        "for line in text.split(\"\\n\")[:-1]:\n",
        "    encoder_text.append(line[:-11].lower().lstrip())\n",
        "    decoder_text.append(line[-11:] + \".\") # 最終位置に\".\"を付加します。"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力文字列\n",
        "encoder_text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kx7aFhiv-Vi",
        "outputId": "cd8e2fed-cf7c-4798-abca-eaabd9afa549"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['september 27, 1994           ',\n",
              " 'august 19, 2003              ',\n",
              " '2/10/93                      ',\n",
              " '10/31/90                     ',\n",
              " 'tuesday, september 25, 1984  ']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解文字列\n",
        "decoder_text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WakMEXnFwBtJ",
        "outputId": "15cd4549-d240-4186-ca83-98247f63a6fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_1994-09-27.',\n",
              " '_2003-08-19.',\n",
              " '_1993-02-10.',\n",
              " '_1990-10-31.',\n",
              " '_1984-09-25.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoder_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__z2sU9ptQh",
        "outputId": "bc7d626f-59f7-49ae-d6c3-0c150c52a49a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenizer"
      ],
      "metadata": {
        "id": "GvrE2a4y45A-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4daI9TvCra2l"
      },
      "source": [
        "class Tokenizer():\n",
        "\n",
        "    def __init__(self, text_list):\n",
        "        self.text_list = text_list\n",
        "        # 文字列を文字に分解しリスト化\n",
        "        self.create_char_list()\n",
        "        \n",
        "        # 出現文字にidを対応させる\n",
        "        self.create_char_id_dict()\n",
        "\n",
        "\n",
        "    def pad_text(self, text):\n",
        "        # 文末の空白をpad文字で埋める\n",
        "        last_char_idx = len(text.strip())\n",
        "        text = text[:last_char_idx] + \"＠\" * (len(text) - last_char_idx)\n",
        "        return text\n",
        "\n",
        "\n",
        "    def create_char_list(self):\n",
        "        # 入力文字列を文字に分解する\n",
        "        self.char_list = []\n",
        "        for text in self.text_list:\n",
        "            text = self.pad_text(text) # 文末の空白をpad文字で埋める\n",
        "            self.char_list.append(list(text)) # 文字に分解しリスト化\n",
        "\n",
        "    \n",
        "    def create_char_id_dict(self):\n",
        "        # 出現文字にidを対応させる\n",
        "        self.id_char_dict = dict()\n",
        "        self.char_id_dict = dict()\n",
        "        self.unique_char = np.unique(self.char_list)\n",
        "        \n",
        "        for id, c in enumerate(self.unique_char):\n",
        "            self.id_char_dict[id] = c\n",
        "            self.char_id_dict[c] = id\n",
        "\n",
        "\n",
        "    def attention_mask(self):\n",
        "        # attention_maskを作る\n",
        "        attention_mask = []\n",
        "        for line in self.char_list:\n",
        "            chars = np.array(line) # 文字リストをnp.array化\n",
        "            attention_mask.append((chars != \"＠\") * 1) # 文字が＠ではない場所が1となる\n",
        "        return np.array(attention_mask)\n",
        "\n",
        "\n",
        "    def tokenize(self, text_list):\n",
        "        # 文字をidに変換する\n",
        "        token_list = []\n",
        "        for text in text_list:\n",
        "            token_list.append([self.char_id_dict[c] for c in text])\n",
        "\n",
        "        return np.array(token_list)\n",
        "\n",
        "\n",
        "    def detokenize(self, token_list):\n",
        "        # idを文字に変換する\n",
        "        char_list = []\n",
        "        for line in token_list:\n",
        "            char_list.append([self.id_char_dict[t] for t in line])\n",
        "        return char_list"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_tokenizer = Tokenizer(encoder_text)\n",
        "encoder_token_list = encoder_tokenizer.tokenize(encoder_text)\n",
        "encoder_attention_mask = encoder_tokenizer.attention_mask()\n",
        "encoder_num_char = encoder_tokenizer.unique_char.shape[0]\n",
        "encoder_max_len = encoder_token_list.shape[1]\n",
        "\n",
        "decoder_tokenizer = Tokenizer(decoder_text)\n",
        "decoder_token_list = decoder_tokenizer.tokenize(decoder_text)\n",
        "decoder_attention_mask = decoder_tokenizer.attention_mask()\n",
        "decoder_num_char = decoder_tokenizer.unique_char.shape[0]\n",
        "decoder_max_len = decoder_token_list.shape[1] - 1\n",
        "\n",
        "\n",
        "# 入力token \n",
        "# 5000個分のデータをvalidationデータとして取り分けておきます。\n",
        "\n",
        "tr_token_dict = {\n",
        "    \"encoder_input_ids\": encoder_token_list[:-5000],\n",
        "    \"encoder_attention_mask\": encoder_attention_mask[:-5000],\n",
        "    \"decoder_input_ids\": decoder_token_list[:-5000, :-1],\n",
        "    \"decoder_attention_mask\":decoder_attention_mask[:-5000, :-1]\n",
        "    }\n",
        "\n",
        "val_token_dict = {\n",
        "    \"encoder_input_ids\": encoder_token_list[-5000:],\n",
        "    \"encoder_attention_mask\": encoder_attention_mask[-5000:],\n",
        "    \"decoder_input_ids\": decoder_token_list[-5000:, :-1],\n",
        "    \"decoder_attention_mask\":decoder_attention_mask[-5000:, :-1]\n",
        "    }\n",
        "\n",
        "# 正解token\n",
        "tr_decoder_output_ids = decoder_token_list[:-5000, 1:]\n",
        "val_decoder_output_ids = decoder_token_list[-5000:, 1:]"
      ],
      "metadata": {
        "id": "U6gUE4EHDofE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder側の入力と正解文字列のtokenを一個分ずらしています。\n",
        "decoder_tokenizer.detokenize([decoder_token_list[0, :-1], tr_decoder_output_ids[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvsyiruUqmw6",
        "outputId": "08112a72-7c25-4bf5-97b0-764af7671272"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['_', '1', '9', '9', '4', '-', '0', '9', '-', '2', '7'],\n",
              " ['1', '9', '9', '4', '-', '0', '9', '-', '2', '7', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, v in tr_token_dict.items():\n",
        "    print(f\"{key}, {v.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr9ahCHTCXon",
        "outputId": "48ee4e1e-fead-43cd-a064-8bd017a12301"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_ids, (45000, 29)\n",
            "encoder_attention_mask, (45000, 29)\n",
            "decoder_input_ids, (45000, 11)\n",
            "decoder_attention_mask, (45000, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder側の入力文字列の最大長と使用する文字の種類\n",
        "encoder_max_len, encoder_num_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXUir1oxCCV6",
        "outputId": "24f9fa55-fb64-4445-f4bd-a6a0f0740328"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder側の入力文字列の最大長と使用する文字の種類\n",
        "decoder_max_len, decoder_num_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8v6VHmE_6nJ",
        "outputId": "24e50a58-d52f-4c6c-9b5c-5e4e4ad93111"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf.data.Dataset"
      ],
      "metadata": {
        "id": "O2l8kLi6_PX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(x, y=None, dataset=\"valid\"):\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    if dataset == \"train\":\n",
        "        ds = ds.shuffle(512)\n",
        "    ds = ds.batch(64)\n",
        "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "lY7xCIVs_SjZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_ds = get_dataset(x=tr_token_dict, y=tr_decoder_output_ids, dataset=\"train\")\n",
        "val_ds = get_dataset(x=val_token_dict, y=val_decoder_output_ids, dataset=\"valid\")"
      ],
      "metadata": {
        "id": "Ixpknrx8_SUj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(tr_ds.as_numpy_iterator())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQpPCHAspFVR",
        "outputId": "828e37c5-b5e9-46dc-b7ff-2435d6d1dde4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'decoder_attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              "  'decoder_input_ids': array([[12,  3, 11, 10,  6,  0,  2,  5,  0,  4,  9],\n",
              "         [12,  3, 11, 10,  9,  0,  2,  7,  0,  2,  3],\n",
              "         [12,  3, 11, 11,  3,  0,  2,  3,  0,  2,  4],\n",
              "         [12,  3, 11, 10,  7,  0,  2,  9,  0,  3,  5],\n",
              "         [12,  3, 11, 10,  5,  0,  2,  3,  0,  3,  6],\n",
              "         [12,  4,  2,  2,  6,  0,  3,  4,  0,  4,  8],\n",
              "         [12,  3, 11, 10, 11,  0,  2, 10,  0,  2,  5],\n",
              "         [12,  4,  2,  2,  2,  0,  2,  5,  0,  3,  7],\n",
              "         [12,  3, 11, 10, 11,  0,  3,  3,  0,  3,  5],\n",
              "         [12,  3, 11,  9,  3,  0,  2, 11,  0,  3, 11],\n",
              "         [12,  3, 11, 11,  8,  0,  3,  2,  0,  3,  5],\n",
              "         [12,  3, 11,  9, 10,  0,  3,  4,  0,  2,  4],\n",
              "         [12,  3, 11, 11,  2,  0,  2,  6,  0,  2, 10],\n",
              "         [12,  3, 11, 11,  8,  0,  2,  9,  0,  5,  3],\n",
              "         [12,  3, 11, 11,  7,  0,  2,  5,  0,  3,  6],\n",
              "         [12,  4,  2,  3,  8,  0,  2, 11,  0,  4,  7],\n",
              "         [12,  4,  2,  3,  5,  0,  3,  4,  0,  2,  3],\n",
              "         [12,  4,  2,  3,  3,  0,  2, 10,  0,  3,  6],\n",
              "         [12,  4,  2,  2,  7,  0,  3,  2,  0,  5,  2],\n",
              "         [12,  3, 11,  9,  2,  0,  2,  3,  0,  3, 10],\n",
              "         [12,  3, 11, 10,  4,  0,  3,  3,  0,  3,  5],\n",
              "         [12,  4,  2,  2, 10,  0,  2,  9,  0,  4, 11],\n",
              "         [12,  3, 11,  9,  7,  0,  2,  7,  0,  2,  3],\n",
              "         [12,  4,  2,  2,  7,  0,  2,  3,  0,  4, 11],\n",
              "         [12,  4,  2,  2,  2,  0,  3,  2,  0,  4,  3],\n",
              "         [12,  3, 11, 11, 10,  0,  2,  9,  0,  3,  5],\n",
              "         [12,  3, 11, 11,  9,  0,  2,  8,  0,  4,  9],\n",
              "         [12,  3, 11, 10,  8,  0,  2,  3,  0,  2,  5],\n",
              "         [12,  3, 11, 10,  3,  0,  2, 11,  0,  5,  2],\n",
              "         [12,  4,  2,  2,  3,  0,  2,  9,  0,  3, 11],\n",
              "         [12,  3, 11,  9, 10,  0,  3,  3,  0,  3,  8],\n",
              "         [12,  3, 11, 10,  7,  0,  2, 11,  0,  4,  6],\n",
              "         [12,  3, 11,  9, 10,  0,  2,  9,  0,  3,  2],\n",
              "         [12,  3, 11, 11,  5,  0,  2,  5,  0,  3,  6],\n",
              "         [12,  4,  2,  3,  4,  0,  2,  6,  0,  2,  7],\n",
              "         [12,  3, 11,  9, 10,  0,  2,  8,  0,  5,  2],\n",
              "         [12,  3, 11,  9,  8,  0,  2,  9,  0,  3,  8],\n",
              "         [12,  3, 11,  9,  7,  0,  2, 11,  0,  4,  9],\n",
              "         [12,  4,  2,  3,  4,  0,  2,  5,  0,  3,  9],\n",
              "         [12,  4,  2,  2,  2,  0,  2,  7,  0,  4,  2],\n",
              "         [12,  3, 11, 11,  9,  0,  2,  8,  0,  2,  6],\n",
              "         [12,  3, 11,  9, 11,  0,  3,  4,  0,  4, 10],\n",
              "         [12,  3, 11, 10, 10,  0,  2,  3,  0,  3,  8],\n",
              "         [12,  3, 11, 11,  6,  0,  2,  4,  0,  3,  3],\n",
              "         [12,  4,  2,  3,  8,  0,  2,  6,  0,  3,  5],\n",
              "         [12,  4,  2,  3,  8,  0,  2,  5,  0,  3,  4],\n",
              "         [12,  3, 11, 11,  8,  0,  2,  3,  0,  4,  9],\n",
              "         [12,  4,  2,  3,  2,  0,  2,  6,  0,  4, 10],\n",
              "         [12,  3, 11,  9,  2,  0,  2, 11,  0,  4, 10],\n",
              "         [12,  3, 11, 11, 10,  0,  2,  8,  0,  4,  4],\n",
              "         [12,  3, 11, 11,  2,  0,  2, 10,  0,  3,  8],\n",
              "         [12,  4,  2,  2, 10,  0,  2,  3,  0,  3,  6],\n",
              "         [12,  3, 11, 10,  5,  0,  2,  5,  0,  3,  5],\n",
              "         [12,  4,  2,  3,  3,  0,  2,  8,  0,  4,  9],\n",
              "         [12,  3, 11,  9,  3,  0,  2,  7,  0,  3,  6],\n",
              "         [12,  3, 11, 10,  2,  0,  2, 10,  0,  3,  8],\n",
              "         [12,  3, 11,  9,  6,  0,  3,  2,  0,  4,  6],\n",
              "         [12,  4,  2,  2,  4,  0,  2,  5,  0,  4,  2],\n",
              "         [12,  3, 11, 10,  3,  0,  2,  9,  0,  3,  3],\n",
              "         [12,  3, 11, 11,  5,  0,  3,  4,  0,  2,  9],\n",
              "         [12,  4,  2,  2,  4,  0,  2,  8,  0,  2,  9],\n",
              "         [12,  3, 11, 10,  7,  0,  3,  3,  0,  4,  3],\n",
              "         [12,  4,  2,  2,  9,  0,  2,  3,  0,  5,  2],\n",
              "         [12,  3, 11, 11,  7,  0,  2,  3,  0,  3,  2]]),\n",
              "  'encoder_attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "         [1, 1, 1, ..., 0, 0, 0],\n",
              "         [1, 1, 1, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1, ..., 0, 0, 0],\n",
              "         [1, 1, 1, ..., 0, 0, 0],\n",
              "         [1, 1, 1, ..., 0, 0, 0]]),\n",
              "  'encoder_input_ids': array([[24, 13, 28, ...,  0,  0,  0],\n",
              "         [ 8,  2,  4, ...,  0,  0,  0],\n",
              "         [33, 17, 16, ...,  0,  0,  0],\n",
              "         ...,\n",
              "         [25, 26, 32, ...,  0,  0,  0],\n",
              "         [ 4,  2,  6, ...,  0,  0,  0],\n",
              "         [22, 13, 25, ...,  0,  0,  0]])},\n",
              " array([[ 3, 11, 10,  6,  0,  2,  5,  0,  4,  9,  1],\n",
              "        [ 3, 11, 10,  9,  0,  2,  7,  0,  2,  3,  1],\n",
              "        [ 3, 11, 11,  3,  0,  2,  3,  0,  2,  4,  1],\n",
              "        [ 3, 11, 10,  7,  0,  2,  9,  0,  3,  5,  1],\n",
              "        [ 3, 11, 10,  5,  0,  2,  3,  0,  3,  6,  1],\n",
              "        [ 4,  2,  2,  6,  0,  3,  4,  0,  4,  8,  1],\n",
              "        [ 3, 11, 10, 11,  0,  2, 10,  0,  2,  5,  1],\n",
              "        [ 4,  2,  2,  2,  0,  2,  5,  0,  3,  7,  1],\n",
              "        [ 3, 11, 10, 11,  0,  3,  3,  0,  3,  5,  1],\n",
              "        [ 3, 11,  9,  3,  0,  2, 11,  0,  3, 11,  1],\n",
              "        [ 3, 11, 11,  8,  0,  3,  2,  0,  3,  5,  1],\n",
              "        [ 3, 11,  9, 10,  0,  3,  4,  0,  2,  4,  1],\n",
              "        [ 3, 11, 11,  2,  0,  2,  6,  0,  2, 10,  1],\n",
              "        [ 3, 11, 11,  8,  0,  2,  9,  0,  5,  3,  1],\n",
              "        [ 3, 11, 11,  7,  0,  2,  5,  0,  3,  6,  1],\n",
              "        [ 4,  2,  3,  8,  0,  2, 11,  0,  4,  7,  1],\n",
              "        [ 4,  2,  3,  5,  0,  3,  4,  0,  2,  3,  1],\n",
              "        [ 4,  2,  3,  3,  0,  2, 10,  0,  3,  6,  1],\n",
              "        [ 4,  2,  2,  7,  0,  3,  2,  0,  5,  2,  1],\n",
              "        [ 3, 11,  9,  2,  0,  2,  3,  0,  3, 10,  1],\n",
              "        [ 3, 11, 10,  4,  0,  3,  3,  0,  3,  5,  1],\n",
              "        [ 4,  2,  2, 10,  0,  2,  9,  0,  4, 11,  1],\n",
              "        [ 3, 11,  9,  7,  0,  2,  7,  0,  2,  3,  1],\n",
              "        [ 4,  2,  2,  7,  0,  2,  3,  0,  4, 11,  1],\n",
              "        [ 4,  2,  2,  2,  0,  3,  2,  0,  4,  3,  1],\n",
              "        [ 3, 11, 11, 10,  0,  2,  9,  0,  3,  5,  1],\n",
              "        [ 3, 11, 11,  9,  0,  2,  8,  0,  4,  9,  1],\n",
              "        [ 3, 11, 10,  8,  0,  2,  3,  0,  2,  5,  1],\n",
              "        [ 3, 11, 10,  3,  0,  2, 11,  0,  5,  2,  1],\n",
              "        [ 4,  2,  2,  3,  0,  2,  9,  0,  3, 11,  1],\n",
              "        [ 3, 11,  9, 10,  0,  3,  3,  0,  3,  8,  1],\n",
              "        [ 3, 11, 10,  7,  0,  2, 11,  0,  4,  6,  1],\n",
              "        [ 3, 11,  9, 10,  0,  2,  9,  0,  3,  2,  1],\n",
              "        [ 3, 11, 11,  5,  0,  2,  5,  0,  3,  6,  1],\n",
              "        [ 4,  2,  3,  4,  0,  2,  6,  0,  2,  7,  1],\n",
              "        [ 3, 11,  9, 10,  0,  2,  8,  0,  5,  2,  1],\n",
              "        [ 3, 11,  9,  8,  0,  2,  9,  0,  3,  8,  1],\n",
              "        [ 3, 11,  9,  7,  0,  2, 11,  0,  4,  9,  1],\n",
              "        [ 4,  2,  3,  4,  0,  2,  5,  0,  3,  9,  1],\n",
              "        [ 4,  2,  2,  2,  0,  2,  7,  0,  4,  2,  1],\n",
              "        [ 3, 11, 11,  9,  0,  2,  8,  0,  2,  6,  1],\n",
              "        [ 3, 11,  9, 11,  0,  3,  4,  0,  4, 10,  1],\n",
              "        [ 3, 11, 10, 10,  0,  2,  3,  0,  3,  8,  1],\n",
              "        [ 3, 11, 11,  6,  0,  2,  4,  0,  3,  3,  1],\n",
              "        [ 4,  2,  3,  8,  0,  2,  6,  0,  3,  5,  1],\n",
              "        [ 4,  2,  3,  8,  0,  2,  5,  0,  3,  4,  1],\n",
              "        [ 3, 11, 11,  8,  0,  2,  3,  0,  4,  9,  1],\n",
              "        [ 4,  2,  3,  2,  0,  2,  6,  0,  4, 10,  1],\n",
              "        [ 3, 11,  9,  2,  0,  2, 11,  0,  4, 10,  1],\n",
              "        [ 3, 11, 11, 10,  0,  2,  8,  0,  4,  4,  1],\n",
              "        [ 3, 11, 11,  2,  0,  2, 10,  0,  3,  8,  1],\n",
              "        [ 4,  2,  2, 10,  0,  2,  3,  0,  3,  6,  1],\n",
              "        [ 3, 11, 10,  5,  0,  2,  5,  0,  3,  5,  1],\n",
              "        [ 4,  2,  3,  3,  0,  2,  8,  0,  4,  9,  1],\n",
              "        [ 3, 11,  9,  3,  0,  2,  7,  0,  3,  6,  1],\n",
              "        [ 3, 11, 10,  2,  0,  2, 10,  0,  3,  8,  1],\n",
              "        [ 3, 11,  9,  6,  0,  3,  2,  0,  4,  6,  1],\n",
              "        [ 4,  2,  2,  4,  0,  2,  5,  0,  4,  2,  1],\n",
              "        [ 3, 11, 10,  3,  0,  2,  9,  0,  3,  3,  1],\n",
              "        [ 3, 11, 11,  5,  0,  3,  4,  0,  2,  9,  1],\n",
              "        [ 4,  2,  2,  4,  0,  2,  8,  0,  2,  9,  1],\n",
              "        [ 3, 11, 10,  7,  0,  3,  3,  0,  4,  3,  1],\n",
              "        [ 4,  2,  2,  9,  0,  2,  3,  0,  5,  2,  1],\n",
              "        [ 3, 11, 11,  7,  0,  2,  3,  0,  3,  2,  1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "M3u_HxuWKhQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### layers"
      ],
      "metadata": {
        "id": "D_y8u17P5MP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderSelfAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    encoder側のself attention\n",
        "    Attributes:\n",
        "        weight_dim: 入力に積算する重みの次元 (int)\n",
        "        num_heads: multi head attentionのhead数 (int)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, weight_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.weight_dim = weight_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "\n",
        "    def split_transpose(self, x):\n",
        "        \"\"\"\n",
        "        xをheadの数に分割し、後の積のため転置する\n",
        "        Args:  \n",
        "            x: tensor (batch_size, max_length, weight_dim)\n",
        "        Returns: \n",
        "            x: tensor (batch_size, num_heads, max_length, weight_dim/num_heads)\n",
        "        \"\"\"\n",
        "        x_shape = tf.shape(x)\n",
        "        x = tf.reshape(x, [x_shape[0], x_shape[1], self.num_heads, -1])\n",
        "        x = tf.transpose(x, perm=[0,2,1,3])\n",
        "        return x\n",
        "\n",
        "   \n",
        "    def create_mask_for_pad(self, attention_mask1, attention_mask2):\n",
        "        \"\"\"\n",
        "        paddingの位置を無視する為のmaskを作る\n",
        "        Args: \n",
        "            attention_mask1: tensor (batch_size, max_length1)  padの位置 = 0\n",
        "            attention_mask2: tensor (batch_size, max_length2)  padの位置 = 0\n",
        "        Returns:\n",
        "            (batch_size, num_heads, max_length1, max_length2)  padの位置 = True\n",
        "        Note:\n",
        "            #1 　(batch_size, max_length1, max_length2)のmaskを作り\n",
        "            #2 　headの数だけrepeatし\n",
        "            #3 　0,1を反転させる\n",
        "        \"\"\"\n",
        "        # mask1: (batch_size, max_length1, 1)\n",
        "        # mask2: (batch_size, 1, max_length2) に変形する\n",
        "        mask1 = tf.reshape(attention_mask1, [tf.shape(attention_mask1)[0], -1, 1])\n",
        "        mask2 = tf.reshape(attention_mask2, [tf.shape(attention_mask2)[0], 1, -1])\n",
        "\n",
        "        p_mask = mask1 * mask2  #1\n",
        "        p_mask = tf.repeat(p_mask[:,None,:,:], self.num_heads, axis=1)  #2\n",
        "        p_mask = 1 - p_mask  #3\n",
        "        return tf.cast(p_mask, tf.bool)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.wq = self.add_weight(\n",
        "            \"wq\", shape=[input_shape[-1], self.weight_dim])\n",
        "        self.wk = self.add_weight(\n",
        "            \"wk\", shape=[input_shape[-1], self.weight_dim])\n",
        "        self.wv = self.add_weight(\n",
        "            \"wv\", shape=[input_shape[-1], self.weight_dim])\n",
        "        self.wo = self.add_weight(\n",
        "            \"wo\", shape=[self.weight_dim, input_shape[-1]])\n",
        "        super().build(input_shape)\n",
        "        \n",
        "        \n",
        "    def call(self, input, attention_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: tensor (batch_size, max_length, hidden_dim)\n",
        "            attention_mask: tensor (batch_size, max_length) padの位置 = 0\n",
        "        \n",
        "        Returns:\n",
        "            tensor (batch_size, max_length, hidden_dim)\n",
        "        \"\"\"\n",
        "        q = tf.matmul(input, self.wq)\n",
        "        k = tf.matmul(input, self.wk)\n",
        "        v = tf.matmul(input, self.wv)\n",
        "\n",
        "        q = self.split_transpose(q)\n",
        "        k = self.split_transpose(k)\n",
        "        v = self.split_transpose(v)\n",
        "\n",
        "        p_mask = self.create_mask_for_pad(attention_mask, attention_mask)\n",
        "        mask = tf.cast(p_mask, tf.float32)\n",
        "\n",
        "        logit = tf.matmul(q, k, transpose_b=True)\n",
        "        logit += logit.dtype.min * mask   # set pad position to \"-inf\"\n",
        "\n",
        "        attention_weight = tf.nn.softmax(\n",
        "            logit / tf.sqrt(tf.cast(self.weight_dim, tf.float32)))\n",
        "        multi_context_vec = tf.matmul(attention_weight, v)\n",
        "        \n",
        "        input_shape = tf.shape(input)\n",
        "        multi_context_vec = tf.transpose(multi_context_vec, perm=[0,2,1,3])\n",
        "        concat_vec = tf.reshape(\n",
        "            multi_context_vec, \n",
        "            shape=[input_shape[0], input_shape[1], self.weight_dim]\n",
        "            )\n",
        "        encoded_vec = tf.matmul(concat_vec, self.wo)\n",
        "        return encoded_vec\n",
        "\n",
        "\n",
        "class DecoderSelfAttention(EncoderSelfAttention):\n",
        "    \"\"\"\n",
        "    decoder側のself attention\n",
        "    Attributes:\n",
        "        weight_dim: 入力に積算する重みの次元 (int)\n",
        "        num_heads: multi head attentionのhead数 (int)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, weight_dim, num_heads, **kwargs):\n",
        "        super().__init__(weight_dim, num_heads, **kwargs)\n",
        "\n",
        "\n",
        "    def create_mask_for_future_input(self, input):\n",
        "        \"\"\"\n",
        "        自身より未来のinputを参照しない為のmaskを作る\n",
        "        Args:\n",
        "            input: tensor (batch_size, num_heads, max_length, max_length)\n",
        "        Returns:\n",
        "            tensor (batch_size, num_heads, max_length, max_length) maskの位置 = True\n",
        "        Notes:\n",
        "            右上三角行列 - 対角行列　＝　未来時刻の値が1のマスク行列 (f-mask)\n",
        "            [[0, 1, 1, 1]\n",
        "            [0, 0, 1, 1]\n",
        "            [0, 0, 0, 1] \n",
        "            [0, 0, 0, 0]]\n",
        "        \"\"\"\n",
        "        ones = tf.ones(tf.shape(input))\n",
        "\n",
        "        # 右上三角行列 - 対角行列\n",
        "        f_mask = tf.linalg.band_part(ones, 0, -1) \\\n",
        "               - tf.linalg.band_part(ones, 0, 0)\n",
        "        return tf.cast(f_mask, tf.bool)\n",
        "        \n",
        "        \n",
        "    def call(self, input, attention_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: tensor (batch_size, max_length, hidden_dim)\n",
        "            attention_mask: tensor (batch_size, max_length) padの位置 = 0\n",
        "        \n",
        "        Returns:\n",
        "            tensor (batch_size, max_length, hidden_dim)\n",
        "        Notes:\n",
        "            future maskを適用する点でEncoderSelfAttentionのcallと異なる\n",
        "        \"\"\"\n",
        "        q = tf.matmul(input, self.wq)\n",
        "        k = tf.matmul(input, self.wk)\n",
        "        v = tf.matmul(input, self.wv)\n",
        "        \n",
        "        q = self.split_transpose(q)\n",
        "        k = self.split_transpose(k)\n",
        "        v = self.split_transpose(v)\n",
        "\n",
        "        logit = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "        f_mask = self.create_mask_for_future_input(logit) # create future mask\n",
        "        p_mask = self.create_mask_for_pad(attention_mask, attention_mask)\n",
        "        mask = tf.cast(tf.logical_or(f_mask, p_mask), tf.float32)\n",
        "        \n",
        "        logit += logit.dtype.min * mask  # set future or pad position to \"-inf\"\n",
        "\n",
        "        attention_weight = tf.nn.softmax(\n",
        "            logit / tf.sqrt(tf.cast(self.weight_dim, tf.float32)))\n",
        "        multi_context_vec = tf.matmul(attention_weight, v)\n",
        "\n",
        "        input_shape = tf.shape(input)\n",
        "        multi_context_vec = tf.transpose(multi_context_vec, perm=[0,2,1,3])\n",
        "        concat_vec = tf.reshape(\n",
        "            multi_context_vec, \n",
        "            shape=[input_shape[0], input_shape[1], self.weight_dim]\n",
        "            )\n",
        "        encoded_vec = tf.matmul(concat_vec, self.wo)\n",
        "        return encoded_vec\n",
        "\n",
        "\n",
        "class EncoderDecoderAttention(EncoderSelfAttention):\n",
        "    \"\"\"\n",
        "    decoder側のlayer\n",
        "    decoder側のself attentionの出力と共に、encoder側の出力も参照する\n",
        "    Attributes:\n",
        "        weight_dim: 入力に積算する重みの次元 (int)\n",
        "        num_heads: multi head attentionのhead数 (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight_dim, num_heads, **kwargs):\n",
        "        super().__init__(weight_dim, num_heads, **kwargs)\n",
        "        \n",
        "\n",
        "    def call(self, \n",
        "             decoder_input, \n",
        "             decoder_attention_mask, \n",
        "             encoder_output, \n",
        "             encoder_attention_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            decoder_input: tensor (batch_size, decoder_max_length, hidden_dim)\n",
        "            decoder_attention_mask: tensor (batch_size, decoder_max_length) padの位置 = 0\n",
        "            encoder_output: tensor (batch_size, encoder_max_length, hidden_dim)\n",
        "            encoder_attention_mask: tensor (batch_size, decoder_max_length) padの位置 = 0\n",
        "        Returns:\n",
        "            tensor (batch_size, decoder_max_length, hidden_dim)\n",
        "        \"\"\"\n",
        "        \n",
        "        q = tf.matmul(decoder_input, self.wq)\n",
        "        k = tf.matmul(encoder_output, self.wk)\n",
        "        v = tf.matmul(encoder_output, self.wv)\n",
        "\n",
        "        q = self.split_transpose(q)\n",
        "        k = self.split_transpose(k)\n",
        "        v = self.split_transpose(v)\n",
        "\n",
        "        p_mask = self.create_mask_for_pad(decoder_attention_mask, encoder_attention_mask)\n",
        "        mask = tf.cast(p_mask, tf.float32)\n",
        "\n",
        "        logit = tf.matmul(q, k, transpose_b=True)\n",
        "        logit += logit.dtype.min * mask   # set pad position to \"-inf\"\n",
        "\n",
        "        attention_weight = tf.nn.softmax(\n",
        "            logit / tf.sqrt(tf.cast(self.weight_dim, tf.float32)))\n",
        "        multi_context_vec = tf.matmul(attention_weight, v)\n",
        "        \n",
        "        decoder_input_shape = tf.shape(decoder_input)\n",
        "        multi_context_vec = tf.transpose(multi_context_vec, perm=[0,2,1,3])\n",
        "        concat_vec = tf.reshape(\n",
        "            multi_context_vec, \n",
        "            shape=[decoder_input_shape[0], decoder_input_shape[1], self.weight_dim]\n",
        "            )\n",
        "        encoded_vec = tf.matmul(concat_vec, self.wo)\n",
        "        return encoded_vec\n",
        "\n",
        "\n",
        "class LayerNormalizer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    文単位で正規化を行う\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.scale = self.add_weight(\n",
        "            \"scale\", initializer=tf.keras.initializers.Constant(1.))\n",
        "        self.bias = self.add_weight(\n",
        "            \"bias\", initializer=tf.keras.initializers.Constant(0.))\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: tensor (batch_size, max_length, hidden_dim)\n",
        "        \n",
        "        Returns:\n",
        "            tensor (batch_size, max_length, hidden_dim)\n",
        "        \"\"\"\n",
        "        mean = tf.math.reduce_mean(input, axis=[1,2])[:, tf.newaxis, tf.newaxis]\n",
        "        std = tf.math.reduce_std(input, axis=[1,2])[:, tf.newaxis, tf.newaxis]\n",
        "        normalized = (input - mean) / (std + K.epsilon())\n",
        "        output = normalized * self.scale + self.bias\n",
        "        return output\n",
        "\n",
        "\n",
        "class FeedForwardNeuralBlock(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    encoder, decoder両方で使用する全結合layer\n",
        "    Attributes:\n",
        "        hidden_dim: 全結合層の重みの次元\n",
        "        dropout_rate: dropout層のパラメータ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dim, dropout_rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.filter_layer = tf.keras.layers.Dense(\n",
        "            hidden_dim*4, activation=\"relu\", use_bias=True, name=\"filter_layer\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.output_layer = tf.keras.layers.Dense(\n",
        "            hidden_dim, use_bias=True, name=\"output_layer\")\n",
        "        \n",
        "      \n",
        "    def call(self, input):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: tensor (batch_size, max_length, hidden_dim)\n",
        "        Returns\n",
        "            tensor (batch_size, max_length, hidden_dim)\n",
        "        \"\"\"\n",
        "        x = self.filter_layer(input)\n",
        "        x = self.dropout(x)\n",
        "        output = self.output_layer(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "class PositionalEncoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    入力されたtokenベクトルに位置ベクトルを加算するlayer\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    \n",
        "    def positional_vec(self, pos, embd_dim):\n",
        "        \"\"\"\n",
        "        位置ベクトルを計算する\n",
        "        \n",
        "        Args:\n",
        "            pos: 文におけるtokenの位置\n",
        "            embd_dim: tokenベクトルの次元\n",
        "        Returns:\n",
        "            pos_v: np.array (None, pos, embd_dim)\n",
        "                   ブロードキャストの為batch_sizeの次元を先頭に追加する\n",
        "        \"\"\"\n",
        "        pos_v = np.zeros(shape=[pos, embd_dim])\n",
        "        for p in range(pos):\n",
        "            for i in range(embd_dim):\n",
        "                if i % 2 == 0:\n",
        "                    pos_v[p,i] = np.sin(p / np.power(10000, (i / embd_dim)))\n",
        "                else:\n",
        "                    pos_v[p,i] = np.cos(p / np.power(10000, ((i - 1) / embd_dim)))\n",
        "        return pos_v[None,...]\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        pos_vec = self.positional_vec(input_shape[1], input_shape[-1])\n",
        "        self.pos_vec = tf.constant(pos_vec, dtype=tf.float32)\n",
        "        super().build(input_shape)\n",
        "        \n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: embeddingされた文章のtensor (batch_size, max_length, hidden_dim)\n",
        "        Returns:\n",
        "            inputに位置ベクトルを加算したtensor (batch_size, max_length, hidden_dim)\n",
        "        \"\"\"\n",
        "        return tf.add(input, self.pos_vec)"
      ],
      "metadata": {
        "id": "P94C7y6nIuW4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer"
      ],
      "metadata": {
        "id": "MdBcEVMt5Qc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "    \"\"\"\n",
        "    一層のEncoder\n",
        "    Attributes:\n",
        "        at_weight_dim: attention機構で使用する重みの次元 \n",
        "        num_heads: multi head attentionのhead数\n",
        "        ffn_weight_dim: 全結合層の重みの次元。embeddingの次元に一致させる\n",
        "        dropout_rate: dropout層のパラメータ\n",
        "    \"\"\" \n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        at_weight_dim=512, \n",
        "        num_heads=8,\n",
        "        ffn_weight_dim=256, \n",
        "        dropout_rate=0.2,\n",
        "        **kwargs\n",
        "        ):\n",
        "\n",
        "        super().__init__(**kwargs) \n",
        "        self.at_weight_dim = at_weight_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ffn_weight_dim = ffn_weight_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.self_attention = EncoderSelfAttention(\n",
        "            self.at_weight_dim, self.num_heads)\n",
        "        self.layer_norm1 = LayerNormalizer()\n",
        "        self.layer_norm2 = LayerNormalizer()\n",
        "        self.ffn = FeedForwardNeuralBlock(self.ffn_weight_dim, self.dropout_rate)\n",
        "\n",
        "        \n",
        "    def call(self, input, attention_mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: tensor (batch_size, max_length, hidden_dim)\n",
        "            attention_mask: tensor (batch_size, max_length)\n",
        "        Returns:\n",
        "            tensor (batch_size, max_length, hidden_dim)\n",
        "        \"\"\"    \n",
        "        out1 = self.self_attention(input, attention_mask)\n",
        "        out1 = self.layer_norm1(input + out1)\n",
        "\n",
        "        out2 = self.ffn(out1)\n",
        "        out2 = self.layer_norm2(out1 + out2)\n",
        "        return out2\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.models.Model):\n",
        "    \"\"\"\n",
        "    一層のDecoder\n",
        "    Attributes:\n",
        "        at_weight_dim: attention機構で使用する重みの次元 \n",
        "        num_heads: multi head attentionのhead数\n",
        "        ffn_weight_dim: 全結合層の重みの次元。embeddingの次元に一致させる\n",
        "        dropout_rate: dropout層のパラメータ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,  \n",
        "        at_weight_dim=512, \n",
        "        num_heads=8,\n",
        "        ffn_weight_dim=256,\n",
        "        dropout_rate=0.2,\n",
        "        **kwargs\n",
        "        ):\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "        self.at_weight_dim = at_weight_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ffn_weight_dim = ffn_weight_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.self_attention = DecoderSelfAttention(\n",
        "            self.at_weight_dim, self.num_heads)\n",
        "        self.ed_attention = EncoderDecoderAttention(\n",
        "            self.at_weight_dim, self.num_heads)\n",
        "        self.ffn = FeedForwardNeuralBlock(self.ffn_weight_dim, self.dropout_rate)\n",
        "        self.layer_norm1 = LayerNormalizer()\n",
        "        self.layer_norm2 = LayerNormalizer()\n",
        "        self.layer_norm3 = LayerNormalizer()\n",
        "\n",
        "\n",
        "    def call(self, \n",
        "             decoder_input, \n",
        "             decoder_attention_mask, \n",
        "             encoder_output,\n",
        "             encoder_attention_mask\n",
        "             ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            decoder_input: decoder側の入力tensor (batch_size, decoder_max_length, hidden_dim)\n",
        "            decoder_attention_mask: tensor (batch_size, decoder_max_length)\n",
        "            encoder_output: encoder側の最終出力tensor (batch_size, encoder_max_length, hidden_dim)\n",
        "            encoder_attention_mask: tensor (batch_size, encoder_max_length)\n",
        "        \n",
        "        Returns:\n",
        "            tensor (batch_size, decoder_max_length, hidden_dim)\n",
        "        \"\"\"\n",
        "        \n",
        "        out1 = self.self_attention(decoder_input, decoder_attention_mask)\n",
        "        out1 = self.layer_norm1(decoder_input + out1)\n",
        "        \n",
        "        out2 = self.ed_attention(\n",
        "            out1, decoder_attention_mask, encoder_output, encoder_attention_mask)\n",
        "        out2 = self.layer_norm2(out1 + out2)\n",
        "\n",
        "        out3 = self.ffn(out2)\n",
        "        out3 = self.layer_norm3(out2 + out3)\n",
        "        return out3\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.models.Model):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "        encoder_num_vocabs: encoder側の語彙数\n",
        "        decoder_num_vocabs: decoder側の語彙数\n",
        "        hidden_dim: embeddingベクトル及びEncoder, Decoder層の出力ベクトルの次元\n",
        "        at_weight_dim: attention機構で用いる重みの次元\n",
        "        num_heads: multi head attentionのhead数\n",
        "        dropout_rate: dropout層のパラメータ\n",
        "        num_encoders: Encoder層を積み上げる個数\n",
        "        num_decoders: Decoder層を積み上げる個数\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 encoder_num_vocabs,\n",
        "                 decoder_num_vocabs,\n",
        "                 hidden_dim=256,\n",
        "                 at_weight_dim=512, \n",
        "                 num_heads=8,\n",
        "                 dropout_rate=0.2, \n",
        "                 num_encoders=8,\n",
        "                 num_decoders=8,\n",
        "                 **kwargs\n",
        "                 ):\n",
        "        \n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder_num_vocabs = encoder_num_vocabs\n",
        "        self.decoder_num_vocabs = decoder_num_vocabs\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.at_weight_dim = at_weight_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_encoders = num_encoders\n",
        "        self.num_decoders = num_decoders\n",
        "\n",
        "        self.encoder_embedding_layer = tf.keras.layers.Embedding(\n",
        "            encoder_num_vocabs, hidden_dim)\n",
        "        self.decoder_embedding_layer = tf.keras.layers.Embedding(\n",
        "            decoder_num_vocabs, hidden_dim)\n",
        "        self.encoder_pe_layer = PositionalEncoder()\n",
        "        self.decoder_pe_layer = PositionalEncoder()\n",
        "\n",
        "        \n",
        "        self.encoders_list = []\n",
        "        self.decoders_list = []\n",
        "\n",
        "        for _ in range(self.num_encoders):\n",
        "            self.encoders_list.append(\n",
        "                Encoder(at_weight_dim=at_weight_dim,\n",
        "                        num_heads=num_heads,\n",
        "                        ffn_weight_dim=hidden_dim,\n",
        "                        dropout_rate=dropout_rate)\n",
        "                )\n",
        "            \n",
        "        for _ in range(self.num_decoders):\n",
        "            self.decoders_list.append(\n",
        "                Decoder(at_weight_dim=at_weight_dim,\n",
        "                        num_heads=num_heads,\n",
        "                        ffn_weight_dim=hidden_dim,\n",
        "                        dropout_rate=dropout_rate)\n",
        "                )\n",
        "            \n",
        "        self.vocab_prob_layer = tf.keras.layers.Dense(\n",
        "            decoder_num_vocabs, name=\"vocab_prob_layer\", activation=\"softmax\")\n",
        "        \n",
        "            \n",
        "    def call(self, \n",
        "             encoder_input_ids, \n",
        "             encoder_attention_mask,\n",
        "             decoder_input_ids,\n",
        "             decoder_attention_mask\n",
        "             ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            encoder_input_ids: encoder側の入力token id tensor (batch_size, encoder_max_length)\n",
        "            encoder_attention_mask: tensor (batch_size, encoder_max_length)\n",
        "            decoder_input: decoder側の入力token id tensor (batch_size, decoder_max_length)\n",
        "            decoder_attention_mask: tensor (batch_size, decoder_max_length)\n",
        "        \n",
        "        Returns:\n",
        "            tensor (batch_size, decoder_max_length, hidden_dim)       \n",
        "        \"\"\"\n",
        "        encoder_vec = self.encoder_embedding_layer(encoder_input_ids)\n",
        "        encoder_vec = self.encoder_pe_layer(encoder_vec)\n",
        "\n",
        "        for encoder in self.encoders_list:\n",
        "            encoder_vec = encoder(encoder_vec, encoder_attention_mask)\n",
        "\n",
        "        decoder_vec = self.decoder_embedding_layer(decoder_input_ids)\n",
        "        decoder_vec = self.decoder_pe_layer(decoder_vec)\n",
        "\n",
        "        for decoder in self.decoders_list:\n",
        "            decoder_vec = decoder(\n",
        "                decoder_vec, decoder_attention_mask, encoder_vec, encoder_attention_mask)\n",
        "        \n",
        "        vocab_prob = self.vocab_prob_layer(decoder_vec)\n",
        "        \n",
        "        return {\"vocab_prob\": vocab_prob, \"last_hidden_state\": decoder_vec}"
      ],
      "metadata": {
        "id": "1-NkCKow3tsq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build model"
      ],
      "metadata": {
        "id": "x8ZZL2YR5eR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "    encoder_input_ids = tf.keras.layers.Input(\n",
        "        shape=(encoder_max_len,), dtype=tf.int32, name=\"encoder_input_ids\"\n",
        "        )\n",
        "    encoder_attention_mask = tf.keras.layers.Input(\n",
        "        shape=(encoder_max_len,), dtype=tf.int32, name=\"encoder_attention_mask\"\n",
        "        )\n",
        "    decoder_input_ids = tf.keras.layers.Input(\n",
        "        shape=(decoder_max_len,), dtype=tf.int32, name=\"decoder_input_ids\"\n",
        "        ) \n",
        "    decoder_attention_mask = tf.keras.layers.Input(\n",
        "        shape=(decoder_max_len,), dtype=tf.int32, name=\"decoder_attention_mask\"\n",
        "        )\n",
        "    \n",
        "    transformer = Transformer(\n",
        "                 encoder_num_vocabs=encoder_num_char,\n",
        "                 decoder_num_vocabs=decoder_num_char,\n",
        "                 hidden_dim=64,\n",
        "                 at_weight_dim=128, \n",
        "                 num_heads=4,\n",
        "                 dropout_rate=0.2, \n",
        "                 num_encoders=4,\n",
        "                 num_decoders=4,\n",
        "                 )\n",
        "    \n",
        "    output = transformer(\n",
        "        encoder_input_ids,  \n",
        "        encoder_attention_mask,\n",
        "        decoder_input_ids,\n",
        "        decoder_attention_mask\n",
        "        )\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[encoder_input_ids, \n",
        "                                   encoder_attention_mask,\n",
        "                                   decoder_input_ids,\n",
        "                                   decoder_attention_mask],\n",
        "                           outputs=output[\"vocab_prob\"])\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=[\"acc\"])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "YyvAm1Ow3xKQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zQkcEn1e_Hu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940eccba-c069-4ccf-8b60-a2bb77a3feac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input_ids (InputLayer)  [(None, 29)]        0           []                               \n",
            "                                                                                                  \n",
            " encoder_attention_mask (InputL  [(None, 29)]        0           []                               \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " decoder_input_ids (InputLayer)  [(None, 11)]        0           []                               \n",
            "                                                                                                  \n",
            " decoder_attention_mask (InputL  [(None, 11)]        0           []                               \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " transformer (Transformer)      {'vocab_prob': (Non  661941      ['encoder_input_ids[0][0]',      \n",
            "                                e, 11, 13),                       'encoder_attention_mask[0][0]', \n",
            "                                 'last_hidden_state               'decoder_input_ids[0][0]',      \n",
            "                                ': (None, 11, 64)}                'decoder_attention_mask[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 661,941\n",
            "Trainable params: 661,941\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for weight in model.trainable_weights:\n",
        "    print(weight.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H56uWRUF-ha8",
        "outputId": "29b94e90-e3f3-47d8-b603-22b838fe477a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer/embedding/embeddings:0\n",
            "transformer/embedding_1/embeddings:0\n",
            "transformer/encoder/encoder_self_attention/wq:0\n",
            "transformer/encoder/encoder_self_attention/wk:0\n",
            "transformer/encoder/encoder_self_attention/wv:0\n",
            "transformer/encoder/encoder_self_attention/wo:0\n",
            "transformer/encoder/layer_normalizer/scale:0\n",
            "transformer/encoder/layer_normalizer/bias:0\n",
            "transformer/encoder/layer_normalizer_1/scale:0\n",
            "transformer/encoder/layer_normalizer_1/bias:0\n",
            "transformer/encoder/feed_forward_neural_block/filter_layer/kernel:0\n",
            "transformer/encoder/feed_forward_neural_block/filter_layer/bias:0\n",
            "transformer/encoder/feed_forward_neural_block/output_layer/kernel:0\n",
            "transformer/encoder/feed_forward_neural_block/output_layer/bias:0\n",
            "transformer/encoder_1/encoder_self_attention_1/wq:0\n",
            "transformer/encoder_1/encoder_self_attention_1/wk:0\n",
            "transformer/encoder_1/encoder_self_attention_1/wv:0\n",
            "transformer/encoder_1/encoder_self_attention_1/wo:0\n",
            "transformer/encoder_1/layer_normalizer_2/scale:0\n",
            "transformer/encoder_1/layer_normalizer_2/bias:0\n",
            "transformer/encoder_1/layer_normalizer_3/scale:0\n",
            "transformer/encoder_1/layer_normalizer_3/bias:0\n",
            "transformer/encoder_1/feed_forward_neural_block_1/filter_layer/kernel:0\n",
            "transformer/encoder_1/feed_forward_neural_block_1/filter_layer/bias:0\n",
            "transformer/encoder_1/feed_forward_neural_block_1/output_layer/kernel:0\n",
            "transformer/encoder_1/feed_forward_neural_block_1/output_layer/bias:0\n",
            "transformer/encoder_2/encoder_self_attention_2/wq:0\n",
            "transformer/encoder_2/encoder_self_attention_2/wk:0\n",
            "transformer/encoder_2/encoder_self_attention_2/wv:0\n",
            "transformer/encoder_2/encoder_self_attention_2/wo:0\n",
            "transformer/encoder_2/layer_normalizer_4/scale:0\n",
            "transformer/encoder_2/layer_normalizer_4/bias:0\n",
            "transformer/encoder_2/layer_normalizer_5/scale:0\n",
            "transformer/encoder_2/layer_normalizer_5/bias:0\n",
            "transformer/encoder_2/feed_forward_neural_block_2/filter_layer/kernel:0\n",
            "transformer/encoder_2/feed_forward_neural_block_2/filter_layer/bias:0\n",
            "transformer/encoder_2/feed_forward_neural_block_2/output_layer/kernel:0\n",
            "transformer/encoder_2/feed_forward_neural_block_2/output_layer/bias:0\n",
            "transformer/encoder_3/encoder_self_attention_3/wq:0\n",
            "transformer/encoder_3/encoder_self_attention_3/wk:0\n",
            "transformer/encoder_3/encoder_self_attention_3/wv:0\n",
            "transformer/encoder_3/encoder_self_attention_3/wo:0\n",
            "transformer/encoder_3/layer_normalizer_6/scale:0\n",
            "transformer/encoder_3/layer_normalizer_6/bias:0\n",
            "transformer/encoder_3/layer_normalizer_7/scale:0\n",
            "transformer/encoder_3/layer_normalizer_7/bias:0\n",
            "transformer/encoder_3/feed_forward_neural_block_3/filter_layer/kernel:0\n",
            "transformer/encoder_3/feed_forward_neural_block_3/filter_layer/bias:0\n",
            "transformer/encoder_3/feed_forward_neural_block_3/output_layer/kernel:0\n",
            "transformer/encoder_3/feed_forward_neural_block_3/output_layer/bias:0\n",
            "transformer/decoder/decoder_self_attention/wq:0\n",
            "transformer/decoder/decoder_self_attention/wk:0\n",
            "transformer/decoder/decoder_self_attention/wv:0\n",
            "transformer/decoder/decoder_self_attention/wo:0\n",
            "transformer/decoder/encoder_decoder_attention/wq:0\n",
            "transformer/decoder/encoder_decoder_attention/wk:0\n",
            "transformer/decoder/encoder_decoder_attention/wv:0\n",
            "transformer/decoder/encoder_decoder_attention/wo:0\n",
            "transformer/decoder/feed_forward_neural_block_4/filter_layer/kernel:0\n",
            "transformer/decoder/feed_forward_neural_block_4/filter_layer/bias:0\n",
            "transformer/decoder/feed_forward_neural_block_4/output_layer/kernel:0\n",
            "transformer/decoder/feed_forward_neural_block_4/output_layer/bias:0\n",
            "transformer/decoder/layer_normalizer_8/scale:0\n",
            "transformer/decoder/layer_normalizer_8/bias:0\n",
            "transformer/decoder/layer_normalizer_9/scale:0\n",
            "transformer/decoder/layer_normalizer_9/bias:0\n",
            "transformer/decoder/layer_normalizer_10/scale:0\n",
            "transformer/decoder/layer_normalizer_10/bias:0\n",
            "transformer/decoder_1/decoder_self_attention_1/wq:0\n",
            "transformer/decoder_1/decoder_self_attention_1/wk:0\n",
            "transformer/decoder_1/decoder_self_attention_1/wv:0\n",
            "transformer/decoder_1/decoder_self_attention_1/wo:0\n",
            "transformer/decoder_1/encoder_decoder_attention_1/wq:0\n",
            "transformer/decoder_1/encoder_decoder_attention_1/wk:0\n",
            "transformer/decoder_1/encoder_decoder_attention_1/wv:0\n",
            "transformer/decoder_1/encoder_decoder_attention_1/wo:0\n",
            "transformer/decoder_1/feed_forward_neural_block_5/filter_layer/kernel:0\n",
            "transformer/decoder_1/feed_forward_neural_block_5/filter_layer/bias:0\n",
            "transformer/decoder_1/feed_forward_neural_block_5/output_layer/kernel:0\n",
            "transformer/decoder_1/feed_forward_neural_block_5/output_layer/bias:0\n",
            "transformer/decoder_1/layer_normalizer_11/scale:0\n",
            "transformer/decoder_1/layer_normalizer_11/bias:0\n",
            "transformer/decoder_1/layer_normalizer_12/scale:0\n",
            "transformer/decoder_1/layer_normalizer_12/bias:0\n",
            "transformer/decoder_1/layer_normalizer_13/scale:0\n",
            "transformer/decoder_1/layer_normalizer_13/bias:0\n",
            "transformer/decoder_2/decoder_self_attention_2/wq:0\n",
            "transformer/decoder_2/decoder_self_attention_2/wk:0\n",
            "transformer/decoder_2/decoder_self_attention_2/wv:0\n",
            "transformer/decoder_2/decoder_self_attention_2/wo:0\n",
            "transformer/decoder_2/encoder_decoder_attention_2/wq:0\n",
            "transformer/decoder_2/encoder_decoder_attention_2/wk:0\n",
            "transformer/decoder_2/encoder_decoder_attention_2/wv:0\n",
            "transformer/decoder_2/encoder_decoder_attention_2/wo:0\n",
            "transformer/decoder_2/feed_forward_neural_block_6/filter_layer/kernel:0\n",
            "transformer/decoder_2/feed_forward_neural_block_6/filter_layer/bias:0\n",
            "transformer/decoder_2/feed_forward_neural_block_6/output_layer/kernel:0\n",
            "transformer/decoder_2/feed_forward_neural_block_6/output_layer/bias:0\n",
            "transformer/decoder_2/layer_normalizer_14/scale:0\n",
            "transformer/decoder_2/layer_normalizer_14/bias:0\n",
            "transformer/decoder_2/layer_normalizer_15/scale:0\n",
            "transformer/decoder_2/layer_normalizer_15/bias:0\n",
            "transformer/decoder_2/layer_normalizer_16/scale:0\n",
            "transformer/decoder_2/layer_normalizer_16/bias:0\n",
            "transformer/decoder_3/decoder_self_attention_3/wq:0\n",
            "transformer/decoder_3/decoder_self_attention_3/wk:0\n",
            "transformer/decoder_3/decoder_self_attention_3/wv:0\n",
            "transformer/decoder_3/decoder_self_attention_3/wo:0\n",
            "transformer/decoder_3/encoder_decoder_attention_3/wq:0\n",
            "transformer/decoder_3/encoder_decoder_attention_3/wk:0\n",
            "transformer/decoder_3/encoder_decoder_attention_3/wv:0\n",
            "transformer/decoder_3/encoder_decoder_attention_3/wo:0\n",
            "transformer/decoder_3/feed_forward_neural_block_7/filter_layer/kernel:0\n",
            "transformer/decoder_3/feed_forward_neural_block_7/filter_layer/bias:0\n",
            "transformer/decoder_3/feed_forward_neural_block_7/output_layer/kernel:0\n",
            "transformer/decoder_3/feed_forward_neural_block_7/output_layer/bias:0\n",
            "transformer/decoder_3/layer_normalizer_17/scale:0\n",
            "transformer/decoder_3/layer_normalizer_17/bias:0\n",
            "transformer/decoder_3/layer_normalizer_18/scale:0\n",
            "transformer/decoder_3/layer_normalizer_18/bias:0\n",
            "transformer/decoder_3/layer_normalizer_19/scale:0\n",
            "transformer/decoder_3/layer_normalizer_19/bias:0\n",
            "transformer/vocab_prob_layer/kernel:0\n",
            "transformer/vocab_prob_layer/bias:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fit"
      ],
      "metadata": {
        "id": "uXuapKikBX60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(tr_ds, validation_data=val_ds, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnZZ72BXBOAg",
        "outputId": "b4552ee3-a88c-4e55-abf7-91ac34641ad4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "704/704 [==============================] - 277s 370ms/step - loss: 0.7486 - acc: 0.7105 - val_loss: 0.1575 - val_acc: 0.9451\n",
            "Epoch 2/2\n",
            "704/704 [==============================] - 256s 363ms/step - loss: 0.1440 - acc: 0.9441 - val_loss: 0.0287 - val_acc: 0.9919\n"
          ]
        }
      ]
    }
  ]
}